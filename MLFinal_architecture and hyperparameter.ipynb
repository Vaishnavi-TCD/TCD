{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEiqZqD9ZPIvtzwufYoZ4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaishnavi-TCD/TCD/blob/main/MLFinal_architecture%20and%20hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCKMSQViq10F",
        "outputId": "127ae478-d3d6-4ed8-f161-1bb5dbe08d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.651214 M parameters\n",
            "step 0: train loss 2.6910, val loss 2.6946, train perplexity 14.7471, val perplexity 14.7997\n",
            "step 500: train loss 1.6156, val loss 1.5390, train perplexity 5.0308, val perplexity 4.6599\n",
            "step 1000: train loss 1.3920, val loss 1.3461, train perplexity 4.0230, val perplexity 3.8426\n",
            "step 1500: train loss 1.3045, val loss 1.2728, train perplexity 3.6858, val perplexity 3.5708\n",
            "step 2000: train loss 1.2738, val loss 1.2534, train perplexity 3.5743, val perplexity 3.5022\n",
            "step 2500: train loss 1.2471, val loss 1.2409, train perplexity 3.4803, val perplexity 3.4588\n",
            "step 3000: train loss 1.2364, val loss 1.2377, train perplexity 3.4434, val perplexity 3.4475\n",
            "step 3500: train loss 1.2251, val loss 1.2275, train perplexity 3.4046, val perplexity 3.4126\n",
            "step 4000: train loss 1.2065, val loss 1.2211, train perplexity 3.3418, val perplexity 3.3911\n",
            "step 4500: train loss 1.2004, val loss 1.2238, train perplexity 3.3216, val perplexity 3.4000\n",
            "step 4999: train loss 1.1870, val loss 1.2185, train perplexity 3.2772, val perplexity 3.3820\n",
            "Generated Melody (GPT Model):\n",
            "RfEEDFFEECEDCBCCCCCCEECCDCCARAffEfAfEDRfffREEDFFEEDRFDaFEDDFEECCGCCCARAAGGfRCCCCCDEFFEEDCgFRAAacFECECGCCCCCCEGCGACRGFCCAaARAAAAGGfRDaDCCCCDEFFECCEGCECEDEFECCECREEDCEFFECCECCCGCGACRACCCARGFGAaccccaEFCEEDDCEFECCGFEECGFEEDDEFCCEECCCCCDDDRBCCCCCaCCCEGCECCCCCCCCCARDCCARAAGGDCCRCCCCCCARFFcEEEDEFECCEFECREFECCgEECCCCCaaCCCGACRAGGRFCCFfEEDDEEFECCCCGFGECCCCGFEEEDCCECCCCCCCCDDARFFcBBBBBcDBDCEFECCCGFEECCCCCCDRFFcECCCGFGECGCEFECCCGFEECCCCCGFEECCCARAGGRFFcECCCCdCCGFCEECCCGFECCCCGGFECCCCCCGFEEECCCGFEECCCCCGFEECCCCCGFEECCCCGFEEEECAFGCEEECCCCGFEECCCCCGFEFEEFCCCCCCGFEFECCCCCCdEdCCGFEFEEECCCEFEECCCCGFEEECCCCCCCGFEECCCCCCFEEECCCFEEGECCCCCD\n",
            "RDBfEDEREREEEEECEREEEEEEEECCCCCCGFEFEFECCCGFEFEEFGCFEEFECCCCCGFFEECRCFEFEEECCCCCGFEEFEECCCCGFEAEECCCCCGFEECCCDEEFEEECCCCCCCGFEFEECCCGFEEEECCCCCCCCCCdEFEEECCCGFEEECCCCCCGFEEECCCCCCCCCGFEEEEEEEECCCCCCGFEEEDCEEEFEEFEEECCCCCGFEFEEECCCCCCGFEEERFEECCCCCGFEEEEEEEECCCCGFEEDCEEECCCCCCGFEEEEFECCCCCGFEFEEEEFCCCGFECEEEEEECCCCCGFEEEDCEEEECCCCGFECCCCGFEEEEEEEECCCRCCCGFEEERFEEERFEEEEEECCCCGFEEE\n",
            "RCCCAECECEEEFaRddRdddcBaggCCCCCAECCCCCCAECARCCCDBCBCAECDBEECEEFEEEFFEEEGECCCCCAECCCCGFEEgCCGFEEEEEEfFFGFEEECCCCGFEEFEEEECCCCCGFEEDCEEEEFGFEEEEEAEEEECCCCCCCGFGFEEEEEEAEEECCCEEEEEEEEEEAAEEEEEGFCFCCCCCCCCGFEEDEEEEAGEEEECCCCCCCCGEEEEEEEEEAAECCCCCCGFEECCCaaCREECCCaCCCCCCCCGFGECCCCGFEEEEEEEEAEEEEEDFEEEAEEEEAEEECCCCCGFEEEEEEEEEEAAEEEEEEEEEEEAEEEEEAEEEECCCCCGFCCCCGCFEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEfEdagRFEF\n",
            "RDFDDFDDDRDDDDRaDCDRDaDFFGGGDDDDDDDRDaaCDCFRCCCGEEEEEEEEEEEEgRgAgfGfFfFfFfRFFfFRFfFfFddFRFdFfFFdDDDFDDDCRDaDCDCCGFEREEEEEEEEEEEEERfEEEEREEEEEEEEEEfFGEEEEEEEEEEEEEEEEfEEEEEEEEEEEEERfFFfFEGEfRDDDDRDDaFGFAGGEEEEEEEEEEEEEEEEEEEEEEBEEfEEfEEEEEfEEdRcAAgfGfFfFfFfFfFfaFddFfFfFfFfFfFfFfFfFfFffFffFfFfRFfFffgggggFFddFfFFfaFddRFdFfFfFfFaFddFFfFfFfgagdggFFdgggFFFFFddFfFfFFffFfFfFfFffFfFfFfFfFfRFfffFfFaFgagffffFfFfFfFffFfFfffFffFfFfFfFffffFfFffFfFfFfFFfffffFfFcffFfFfFfFFfFf\n",
            "RFGDDCDFRDCCCCDCDRaaagagGFdddGGaAGDaAGDCaAaagagGFRFGRFGaDaagGFdCddGGgaARaaDFgaggFdagGdFddGFGGFdGgGdFRagGGdCdFGRFGDDCCGRaAaDDDCaaGFdddGGaAGDaAaDEDA\n",
            "RddddaFaaFdddaDdRdddFCaRddaFaFRddaFaaagagGFGdGFdaGGaAaAGDDaRaaDCadddaCagRddFCaFaaagGddFdRdddaaFddaadDRdddaaaFddFaGGdFGGdFGGRFaDdRdddaaFdRdaaFdFaFGGFdFdaaadFaCaddaFCadaaaFdddaaaaaFdFdRddFCaaddaaddFGaaaaaFdddaaaFddaRddddFCaRdFCaFaRdaaFdddadaFaadaaadaaaFaadddddaFdaFRddaFRddFaaaadaFddddFaadadaadadaaCgRddFCaaddaaaFdddFaddFdaaaFddaagdddaGFGGaFaadaaaadaaadaFDCaaGFddaaCaddaaadaaaddaaaadaaadddaF\n",
            "RGDCDCFCRCFGDCDCRFCFGFFFGDCDRAaGRAGDCDCRAaCaCCDCRCaDCDCCFddFaaaaaddaaFdfadddaddaaCCdRGGGGdGaFddCGaFGFGFddCaaGFGGaadaaddaaddaaaCGGdFadaaaaRGaaagGRGaaGFdFGGCDdDDCRCADCCCFdddDdDaRGGgGFdddaddaGFGFGGaaadaadFFdRCDCDCDCaadaaadaddaFFdfadddddaaaadaaaaaaddaaddaaaadaaCCGGdFGGGaadCF\n",
            "RdddddddcaaaRdaadcacacdddaaRdddcfagaRdaaddaaaRadddcagdddcagaaggRfgGgGFddaaaaddFFdfaddddagddaaaagggRdaaaddaadcaaFdaadaaaddaaadaaaaaaaaadddaaaaaadddaGddaaaagFgagdaaaaaCaaaaadaagFgagRcGgddddaaaaaaaaddddFFdfaddddaaaaddaaaaadaCaaagFgRFFaadaaGdGgGGdFddaagaaagaaaddagdRaaaaaaddaadaaaaaadaaGdGRdGddadaaaadaaaaaaaaaddaaadaaaaadaaaaddaaaaddaaaaaaaadaadaaaadaaaaaadaaaaadaaCaaaaaadaddaaaaaaaadaaadaaaaaadaaaaaaadFFddRaadadaaadaadadaaaadaaagaaaddaaaaaaRdaaaaaaaCaaaaaaaaaaRdFddaaaadaaaaaaaadFFadaaaadaafaagaaaaadCaaaaaaaRaaadaaaaaaaadaagaaaaaaaaddaadaaaaaaadaadaaaaaaaddaaaaadaad\n",
            "RDFFFGGGFRAaaaaaaaaaaRaaaaaaaaaaaaadaaaaadaaaaCDaBaaaGdRDaRaaaGaaaaaaaaaaaaaaaaaaCdCGdGFRddCdCddDaaaaaaaaaaaaaaaaaaaadaaaaaaCaaaadaaadaaaaaaaadCaaaaaaadaaaaaaaadaaaaaaadadaaaaaaaFFFffDRfaaaagaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaadaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
            "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\n",
            "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\n",
            "REEDfREDcBRfGfGgAERfffGRfFFFFFGAAEREDgfRDEffGEfEREDDEfEBEffFfGgAcEBRBfEDcBRcBfRBffEfGfREDfREDfDEBBRDcBRfGfEEBfffGfGCBCBAGAGAGBCBfGDDGfEfDfGfGAGRfGfRAcEBRfGfEEBRBAGAGfEfEcBEDcDcBRffGfEDBRDEDfGAEfGABfGRFFFECfEfFfGgAERBffEEEBEDfDEfEEDEDfEffE\n",
            "RcBREEdffEAffgfEcBREddRcdRBgggRfggRdgggffBcdERcBREEdRggggfEfEREEEdcEEdRggfEEdcEEdcdcdEdREEdcddBdcdEdccBEEEdcREEdREEdcdEEEdRgggfEfREEEdRgggfEcBRggEdREcBREffEEcEcBREEdREEddcdcRBBBBBcREEdRcffEdcaaRBffgRBffffffffEEREcdERggggfEfEREdREEdRgggffEREdREEdRfEdREdRcggfEfBREEdRggggfEfBRggggfdcBREEfgRggffEfBRffEfBBccgRgggEEdRgABgRggggffEf\n",
            "RdCdddfFRdRdcFRdddfgaRCagdcccBaagEfgfgagRCagaRccdBgBcBaggdcBRfffdEcaRaaaggRagfFfFdcRFaagFdRdFfdRFFfddccdEREdRaagagddddddfgaRagggEdcBREEdRaagaRdCagdRaaagagFRFFfdRdFfRCcggAg\n",
            "Generated Melody (Unigram Model):\n",
            "CDgcRggaCcfGfCBfFEdFgRdfBGFCFEBBGBcdERRFdgcFCGdDacRDCaDaAcRDFGgGaffD\n",
            "EDGdDcBDcGdRRagBFFFDDCFADRGAGFcaRadFCDEdACfECaEGCFCFADgdAgRDFfBBfDABfEcRAFBEcgfCfDRAARCdfAcRdBFgEGgDgccAfAGcGAcdBdagCdDGggEGBaRDGDRFDFCCDacECccBFRFGAGdfDDEDBdfaEcgEAGDGdcBBAdDAfffFBgCCCaACGcCAGDERgADBcBgBDfdEBEFDAacGcaCfEDRfAGcCdDfDGdDdAaBgDRaafCFDdafEBfBCABafBGGRGcCaGCAGGaEcRFDADfaAAfRfaBCcRcdAFgABGFggGCRABAGFdBCAfREDBaDaGaAgacGBRFccBARccffgDFCaABdBFaRGEAgfBfECEfcFECREfBacAdFFADAFFRARCBECBagDFCDEdFRfECgGCEgRBDEE\n",
            "BAgBGGfBaAgcAdfaBafcEcABBgBagEDFdf\n",
            "GGaCDaARaEFEAfRaAEAgAccGCCaBdFcBFFcGfAgCgGdaDCcgGCBFFAFAfRDcfEgAagcacaCFacAdBfDGaGAdAgBEcFGadDfaA\n",
            "aDcBdFggCgCAfBGDagEEREFAEBdAacGaDffDcfFEggAABfGcgfBaGECdRdGABdfgADgABdDDCFREBBAaCDRfgBGFFgaABdfAccDagAgBAGcDRBfGdEARBEfcfCfd\n",
            "gDcagBRCEfgCREGCaaBAFADAgDgCfBDRgRBdacCgCFBcGa\n",
            "FAfCFEccRDBfFRDdCDBFafcaCaECR\n",
            "BdEafDfGGacAcEBaGADcCDfgRdBBREFgcFAACFfFBgBCgfFcEDFgCgCgFREGEFadfCdRCaFcRRgBCaEfdDAGfadBfgEFCCDBBGFEGgRaBRFDRafdgBfRFgFAgRaDGFagRBdRRdgggaEDCAEFBdcdcgfcccgAEAFADCdCCFRBgdDGCABABBDAfFacEggFcDFgDFgcgAgFFfRgfaRFFREgCFEDGfDCRERGRGBdfFFdcRGcRgBBECgCgdfRAGDRagfCdGgCcggFFgFaafdaFBRgCdFaFAgBEEgdABgdCcECRfcCEfBDgDGREGDcBFaBECGGBFBRBafFDgdEffaEDFRfaBRGCfddfAcFEcEARECfDcdcRRDgDgfcgCaGGAfEaCDRDBARaDGgcdBfGFdBCCgDBcABgGcFDFfccGEaCEGDDgfDCECCfCRgfaRGAcBagfBCaBAdfCGAfadFDfFgCgDDCdAFddEaAfdAdDAfaBCFCDDECdAGaFRaAdcCBaRGGdEDAGfFGDBCGfaEEDDgCDBRDBaERRFGgRCdEgdaDfadAdCcBFdaFAdGCDBgdEDACFfRAAfAdGcAdABaCBdCFAgcDADdgcdgDdCfABBFcAAGDdECCRCEcFCAACRdEfBRDfEDGDfDAGcRAfgAFCRFCAFfccAdaFDRRERFaCABaFGRaBGgcaBDACDaBAcaEEEGBCRGBECRGFcfgEcEfgaDBEfDBCADEdDFRFCBEEDFFDCFCCdDCEEGERdBafcDcRcDFFDaAcdCRaCCAdDdADFAAfRREGRGEFdFBDBdFBCfagfcGBafAdgAaaFgdCFRAdABFARADDEgGEACBFRFDEgECdFBcAffABgFFABAfFggdccgG\n",
            "DcFacACCEaCgRFaRGgFGdBGCACGGGAdFcCaCAafdEDRaDfBGBGFgBDdBBdaAGDdAEDgDfcdACCEAEgaBAgBgaaagfggFDGBAFDdgEdfEcGaFcaCfaDDBaECgGdCfccEcRFDACdFfddERAcBfBABCCDGfgFDFRBCDCDdBBagfCRGfFGRERFfGCGaFcGREDRRfRGfcGcGccEDGBfcgBECcagaADdgaFgAFcGaBBFdRFGRdEAARaFGCFaEaAdRERgDCFafBBfAdEaDEBEFdDCEffRFfRBaEGfGRaBBRFGgGgRcFDDcDFDfdARCafffCRGFgdAdDfCaFcEBDECRdRdFFcDRAFgCFgGDdDcBFgdRaRGGaCcBcDRdccABaEaBAFEaRRDEBFBCDcRDFF\n",
            "cDFADGRgdcDcAfCARRDGGBGdFRdgfEAEDGCcDRCCCBcCFgfAEARRCcBGGBCDfGDAgaDBGFBacEAfDDFGdfDGDFGaGEcEEfFaARRcddBcDgFcERgBccaDCdFBCcGfgBaCaBfEDaCcFcFAAfdABEGGaCAEBaaCDdDDDDcDgfaEFaCACBFDCCdGDAggAdggfggdDFGCGFDcggRRFggdgREdAfFDFAaaCcdfaaGGGdFAggcAEdgCggGREBAgCRgRgAgDDCACdREDcCEfGCFBDaGgfdGffAEADgcCfcAddGDBGEGgaDAGDGdRCFCAagGFCfcfABcAGAcccFaFGfcddFDEdEAacacaBGdBDgcfgCCccgggFEFECRcfACFFdBdafGEdEfaDdgCFBARcBdaADRffBFADAfFRFfEGaDCBFBGgAFBgEagCBBgEFAfEadGaDcRccAdAEABCfCFaafBfCFDdgcAEgCacFDAGRdRBGfDBFGBFDcfDfGcRaDcBccddFGBdaGCDaBCEBCAFFGFAFBGAGFcDEaFgFABdFfDBEfFBRcRRBgffCEffBgDBAFEaRfAdcfEaRafDgaGCDAfACEAcCCAFgDRgCcAABdGGcfBACFdCAdDCfDAgABAdGcDBcEFEFcfCDBcCCdGcccRcBEfAGfERCAfRcREEGAgDfEFBdCDAGCEAERAGgadfACBFAfgdfEaddBcRcBaFgdaBBBadDgFRgadAGdfcAdcRAERCBGfCcDDDaRAAGaCfACdCCECEEEAgCDADcfRaRFdCfaBgcGRDAAGDBCggGdffaBDBARCADaCdRfREagfaEEgFaaBRAEdcRREGEDcAAARAGFGdaadCgaCRREfgfRGaGDFgfGDAcCdCEEaEFRRBcGCffGcCfddBcCcDAfBRBBBgdDaDRGDAgFFcccDGgcEfdERfaDAFRdgGDAEafAFgaRgcfRRaGEAdaRERCEcBRRfdAFcBfFDafaGCDAacAcgGDdCEcGgBRCGdacgGgEBgGFgcBdgREAEgEAgafDDaEaBEFcGcFcCaadADcCAGaaEddcABFFfcgCaFCdCAaRaECAagCFDdDEDBfRaFaBRDDAdDFDFERcDDFREBGfGEDFAfcgAdDDCFBGBFfdEcaCGfDFaddFFcgaCBGCDgdRCgECBdAggacFaBEBfFDaFaRfdFcAGgfCDaGGAgGgEGRARFAAdacgRAgCARECGAffgdFdCBCEDaDAEcaCfAffacgRcFfCfGfCfaDcfFcFFRRRBARcEABAEDcFGCDfCgDDDDRDBCDEEBccDAEgAfBcBgCCcBDcDRRCFfBacAGAAcFfBGCBDDBGCFcRGaGfDgACgRBDDEEERfGRcBaaaAdDFcGCcBFgEdEffdBaARADEfaCgFGDGaBBCCBRgBBAGECBaaBgFdAaddAaAcaDCGGRCFDdfgCEBAGBfEgGaBfRcfddCfCDaDfaCDFfcGAggCBEFFdAEffFfDRGfcgGgERFEdcGcgGcdgaRAAgEFDDAdfRRCBGDGAfD\n",
            "EaDgBFFGCECDDfRDFfcBEfAGdfGFdDFdagccREDEACacAGGFFDGFaAgCfgcGdRREBgBEfDagdfBEEBDdRECfAcdcfcDDFACBgfaEcgagdAfGBgcBaFAfFcRAfBFffEfgcFgfABAcfDcRDRaaFdEDDADfcEDGdaGfCAgCfdaaEGcGRfCCEGRAgRffEABdfEDCAfABcfAEFRfffRDRCGRRcgfafGEACcFGacGBCCgCdGCDCBDgDaRdfAfcGgFBdFEGcfDgdAEBcgfdDgDgaEACFRGfDdDFGAEAcDaEEFERcRFfRGagfaRFGfgaaRCCcRfdCGcdgEfdaffRBcdaEREcBDEfEFaEBBCdCFRdCgCBfAgCCCFFRfBFBAfRRDgFdEdaacagAcdRFfdccgFRdcCfgEGRECddEaAGGGfdRGFDGCcdDCagDgRBBfGGDFRAfgfARRdgDFRdfdAgCGA\n",
            "fGRFfCRfaDcCCDFEEcEaRcDfRfRacafgARaaffEFaCaAFFFDADFCAfRgCdddFFfgECdEcgR\n",
            "GfCdGAgafaaRFgCDadafARBdaBCdfGDGECdfRDgGAACBgBGEBRRgAaDfaAfdCcGdcRRFCDEdaDfADRdGCGRBGBDcGcRDARAEBGEBCgRcGEGDGCGdFDAaRGRRdACBGABDDRgfAAfffDdDcfEGgGgRdffFRfRfCRAcCdfGCcfAdFddBGcdEgdEgddRdBCBRgBDGRdDREgBdaBAEFfdacFFGfaGGRFfffEdERfBDafgEfBRgEEccADCacaDfFaCECdgGfGAcgCGGdERCEgfagADaFAgFFEdafABffERCcRdfEBRDCadEaAgBCdBFgGaRCDBGdEcAgDafDcBfcgDBFFFAFgDDCABGBfRGBADECBgBEGRfggEGfCdaBcfgcFAfcdBEFGCEBBdaaDAEfDagGECFBGcBfGcBRaBgBRaGARRcAAadERGfgaadEFDaCFgFBfdgGGgfDGCfCcAAEDBRCaEGaRaGRadgDgFRRFgcdGdDgDdRCCBBEcFgfFEgEcBEDcagagAdDAfFcDFcDaGgaAaffFadBacFdGcADFgBfRaEBAGRCcEDGdfRRgRAEGDRGBcGGdFaCdaFAcBdcBcccABaDAGcCaaFFdRaAgGDBEBRaDGAfBcAaRdaFccCccEECdBDfddCFdCGfDCCFdDcfDcfafcEdGCAaFGcgFRFcgERFdfcdGcDfDCCEFcCaDGEgCGcDaEBffGFfaaREgGaDgdBDgGEDRRfRBEgABacfDaFECGACfddFgCBaBgCAaDEcaARDdgfcdagFgfGCCCEGARBCDaDEaCcafCREBBCDaFACRGFdgFcfEEddggBcFRffCaCGRRAgCGGgGBDgBFcEcRdDEDAgcfDRaCDDdaAcGcARfCgAdfRREGfAgRFFGEfdCdCRRagdDRDBGdGRaFBaFBGACdfDRRBAaFGGEddDRCCEfEGDDcccdDGBdcdRCCfgBEGaaCDCgcdDGcaDBgDdcFEgERDCAcddadGBaBEAGACBDGaGGDgFEFCAGccDfFDRRdggCdFBDaCDcDgCDfEFCdggRfAREaGdBBGGcaGdgGEADRBRddRFfAEcCBRcadGRfEdgCggdgfFBGAdACBcGRdECGgFaAdD\n",
            "AcBcCERcAaRAfCgaFgffgFBAAddF\n",
            "aGfgAFFCGGBAGDccaCRgGGdcdAECAfCaEdABdADGBEFfBaREBcRDcBgafFaFDDFCdcRdAcgFRdgBFCdaAFcfcAgAgdDCFEaFGgGcggAdBGRgRccGaBdBECABccBCaRADBAGfCDCGAgADaAcGEdCAFfdGGafcDafAADRAGdfgCFRfgaADADcBBFagdDDcfcBGRCFcRCfCacgfRGaDgAGCcBBGBdCDdfGgFcAAfFFFDECEgfCBaDfdgRddDGEfGEFgFABDFEgaCRgGaDafBGdgcDAFfDRaCGaAdRRDcdFdaGADDCRgadfGDGgdGgGDRAEGGacdRFCCgCEgdEAfaaRBfBDDdAgABRBBdBdEGaaGaDCDBDfFRBCEFcDBAcAGAFdGadEBEGdGffDEdcfGARGFgdFBGgREBgaDBECRgCfAadFDFdGCCDEBcAGRRfGCgBRdacfGRAADAGEddEAEfcfGcdDFffGdBfRRFRBdDFcGcBRaFDCdcAACRcggRDFgRDAfaEADddCdGcfgGEFFDRcdRcffCGBCfCdCEcfgCDAdARBBDdEDAGGFcacRAdBgdFBcgFBaECRCgfAafEGdEDFAdFDACcafcccDgfBRfGFERCcCGfDgRdfRBRfdcDFECgGcBacgFcDGgEgDafgAacAfcaBFBDfDRaaGfRgdBGDaBFfDfCdaEgRGdBEddaGdFcDgRgFafGaRaRfDaRDgGdaRAdCgFEfdfEfEDFEGFcFdFBCEfdBDBBadCDEdBgcGcCFdgdBFfcddaCdFcRafdBDRcBERFRCCRRFCDcCgfFfGaGcDCcgEEGFDADBcAFEABCfEFRFDFAEDBFBCggaRCEBAAgCgBGfddadREDdCFAgDcDGFBFDBGdAfBDagcaRCacCgdgECBCFADAfCEgAafDFffCBGFBfCRfffdccFDaDgBGFADGdGaFaaBGgaAfcdcCEaFagBdAagcBCCgdCEgfRECCCDCARcgdRcGREBGadDcDDFAEBdBCBcBGaGBdBAaGdcCRGFGEAfFCAAADFcDcdDBDgBCdccEBBffcDagCfgCAccGBCEABaAgRaFFFEdaERAgFDEDffddRAgGACDfgREddFagBBFEBBCcaFgDdRgRAadCaEdaACdaRdcBCdCEfCDRAgdgagDCfEDadaCDCFCBGdAfGRgERcgGRAGRFcaAEDGfdCRAgfcggFEGCcBAfCDRcFdgBfGRRdcGAAdAGgCFEgAfcCdDBECcGdEfaRFGaBEFEcDRAfCEDfdfggaBcdgBAEEBgfDRaCdRfCdCffFGEAgcEdGEfAAGBAFEFdDfGdgAfGDAaFRFFFcafaFCfEfcAEAFaFaERdRCDRFGDGFCEfgCgBFCBGcEACFEEEGfAfGdagCaGBDdFGGGREaFdCRCCgBFDdEgCRARAcdDfdCE\n",
            "FAfgGDcfEAcdFffCAERABDEGBAcgCdDfcDgGcBaRcERgFRfEDCfFaDcGFgFFCggGCRBEFcgRggagddFdGERDAdgERFgaGgcGaRAfDgGECEfdAccaaCaCAADERDEcgGcgRfccaBEadAaddCREFFDggfcCDFdgBGcEdFdaDFRcFEAdFgcfaBEDdGdBagffGEABgDRdddfGGBfEFEGRaEBGcRRCffAAaEaGaREfBcaFFGFCgFdFECacaRGBEaDdFDdGaGgfcDABBgGRBFdBCDgFBERAfAdRBGdAFdaGFdCAADEgEdEgEEdBfcAABRGggGcBREFEfDBDGDGCgEAAERFcaADgBCaGDdddcCacCBdCAacDacfGBf\n",
            "gGCGFdaFcFGDgDfGFdEgdaEAERGEaDDEaBCaaaFdgAEEfCcRFgBRDGggdB\n",
            "cEDcgCFAERgBEDFAEgRaFDEGcEBcBRcCgcddCfffADDBCCDaaCRFFECBaGRGDfDGFEFagADFBGcFcRGfgfGEDAdAgRCGEgRAgRRaRcFaEAaACCFFDdGDfdEgGFRfAffAaDfcRdBCDDgdBcFBgdEcFECBBgCgdEgcRFCcEEfBdFBfGABafDEDgfCCCdDfdAccDCaBRFARGfAgfEcdcBCGGCRFEBEgDDcRDDaGDgfAGGEFEaFFRaGCaagCCGEDEBFAgFccRdADAFgGgFRgdBBCRDDBadABDEgCfaadFdcFFdFDfgGCfDAEfFdEGBACcFDaCCEgBBAdABGgFRBdaGFDCREDDCaaFEcDFCcAEcGaaRGfDRfdfBCdDBFGRRCCGcBFdEfFABaFFaRBDdcAGGgFFFcEAERCfcRccgdCCAFCcEEfRCddcGCE\n",
            "aAAAdGEBFgD\n",
            "GAadRGGRaAREFEdDCRcDaAEREaDaCFgFGRGREfDFBAFRDGEGFdCAcAAcFAdGBBEfERGBgFBdGcDdaGGBgGcFGcCgCCaGgABdCCEdCEAf\n",
            "CDFcRRfDADccfCEfGfFfCdEgRggadgcGGdCBGARFaCABBaaDaRcCGcRBgFBaEBBEEcfdGcgFadFGAccgFdDcRAgacfaGAgDGgfgdFFEGDCEacBGfCRccCCGBRRCDdGGAdfRBDgREdaFgABfaACdcFcfGGdEEdfcfCEffFcAAREafdacAdBfgGdcFRcEfaDBBAARFgCfGGggfFgREADCcdRaBfFfgaGfCEcEGcdBFDFREgAEGfCEdBBAEBGEGdd\n",
            "cCDfFdffGBFRGEGCDFdgcRaFfGARfRAaBgBFdGaFRRDBBRdBfBEGGAGDgGcgRECaAaGGdGdfFdFaaAfDaRddaBBfRFdgDDRfDGgadcRcgCEgEGfgRAgaAEAGAfBgFDREEGEcgBEGdfgcAFEGcffBaAgEDfEcDgFfERBfgaaBDFcaEaAFARAcFRdCdaBaaEd\n",
            "dFEdFBEdRgDBgdDDaCGGgBDdgagfcdCCEFRCcDFdaagCDFGBaDCFEERRcfRCgdEDAfFEddEcRRAFgGEfBgAEAGCDFEcdDDCcFfgfdRBEfCRfdAEgDGGBaaDAgcfcFEdEABcBRGREAAdgaCaCfRBfFfCDGaDRFFAaBFBcgfadaaGFCdFfGGEdgABAFEfDdGRCAADRBRgdgDAaaRCAfFdADBdcgadBBdgGdGagRRfaDBdCcfaDCFfGaDARdRECFfdRcEccECDRFBgBBAAfBgAEFCBaGBCgEdaGCFBEcdDDFREDDDcFEcDRACgFEcGcDEcADcgECfGfACBdEEgAfCcGRCCFFfRDDFCGcAGgfGcfACABgARgAFDafGgFECAdCdDFfDgGGRcfDdGfCADBRfEagfBffEFBRGCGfCGDBfcdcafCEBdFfgBRcdFDafgEFRCfcGggaFFERACEARAaGARGRCRRDgAFfARRcdfRFDCBFcFdfRaDRfgAGDCRdRfcGRGddDDRBgCBcGaARfRREGcFdccdCACRgGcFERdcgaGGDfDFDAfdaBFAGGEFBGGBEDBAagdDgRaCFfCRfBFfRECCGagfFfdEgERBDaBBcCBgddRcfDcRdAfFFCEgafdBFRfFaafDgFFcagEDADcGaDFGFfGCaRDFadDDAacGdaRdd\n",
            "FCEcdaRfdDBdgRBAgcRFdGGDcdaaddacfEADACaBcccfCFADRAFBfARCFAccARERagaacBfC\n",
            "fGaBacffRFgFdEGDfDdFCCRfgdcdAFEfBaRcAdGEfABRgdEfFafABBaaFAdFdBGdfBDBEREdfFAaFAdgFRdDaGDgBfFAcaaDgGEcBDAfFdcEdgRfBaBgDFAgDgFdABDacdaRdfAgfBGAgFCBFdRdGAgFBdGBCCgcBGcdBFADgfABfDGAABdAagBEEGEcFggBDgaCDggAdBcaBRgBDCaafAffGCdCCfAGgdEEGdEBdERaAEGdfgCdDDfgDBDFDDAfafGECAC\n",
            "gCCERgBBdgaAECDfBFCfCDFfafEDcfDADdfDGRABCcAAcFECFEdDGDGFEBFCcdgAagEGDCEFaaAAcdBBEAFCcBBBDCGREfcGggFccdRdGAAABGGBfCCcFacCGfdGfCFcGcaEAffCgFAGFgfRBdEEAGCBGEBCfdRaEdBRFcAafAEFDFgAffDECBDBDdaFDadaEAdCBgRdGGAgFRaRBFDFAFGdgDDfECEaCFGRdGRGADaBfEcfaCgCAaBgDcGgEAARRffGfRcGEfCgAEFFddRBRdFfgAadCEaAcEfGAAFdFBEABgdBgggFddcDgEaDFEacBaDGAfgGFFAFDFEdFdafDGfgAacdgcRCABFERCcFDCEcdgdDCdgCEDafCFGDCARDaBcfdDBGBgdaGAfDFGddGdcGffcACEABFFREadgfafRBDBEAEcdFBBACRGBBDBDEDABdBgcfBFRgdGffCgDEcBEgCGGgCCEcFDAfADcAFAcAfDgGDCGAfdcdgDBcEcRBcFRaBBEEagCFgEGDFGCAFgdCDdBCaaaBcDGEaAEgEfRFFfFRfEEfdcDcRgGBaEgEGBEdgGFEFFcFfFEDABCcGEgdcdcFAECadBCFaCfCCEGgdccfDgCBcFBEBaFEdfcCGcCBDCCfACGFfECEfRRcCEDEFGdFgRBAgDDBDgaAEBgBBFCFagdaCcfGFRAcGBdEFcEEgfFCggGFGgFRfDCBADBDFRGfCBGEgFagaBfgAaEaCdcFaBEAFBcCBffCADdAaRCcaCgdGcfECBcDFEaAgFAfGEcFdcgEAgRaAcccC\n"
          ]
        }
      ],
      "source": [
        "#saving the generated token in txt file\n",
        "# perplexity and base line model included\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.2\n",
        "\n",
        "n_embd= 256\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('inputMelodiesAugmented.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(loss)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(losses[split]) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# # generate from the model\n",
        "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "# print(\"Generated Melody (GPT Model):\")\n",
        "# print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "\n",
        "# # Generate melody using unigram baseline\n",
        "# print(\"Generated Melody (Unigram Model):\")\n",
        "# print(unigram_generate(500))\n",
        "\n",
        "# Generate the entire sequence from the GPT model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "gpt_generated_tokens = []\n",
        "\n",
        "# Generate tokens continuously with a maximum limit\n",
        "max_tokens = 10000  # Adjust as needed\n",
        "for _ in range(max_tokens):\n",
        "    new_token = m.generate(context, max_new_tokens=1)[0][-1].item()  # Generate one token at a time\n",
        "    gpt_generated_tokens.append(new_token)\n",
        "    context = torch.cat((context, torch.tensor([[new_token]], device=device)), dim=1)\n",
        "\n",
        "# Decode and save GPT-generated melody\n",
        "gpt_melody = decode(gpt_generated_tokens)\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(gpt_melody)\n",
        "with open(\"gpt_generated_melody.txt\", \"w\") as f:\n",
        "    f.write(gpt_melody)\n",
        "\n",
        "# Generate the entire sequence using the unigram baseline\n",
        "baseline_generated_tokens = []\n",
        "for _ in range(max_tokens):\n",
        "    new_token = random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]\n",
        "    baseline_generated_tokens.append(new_token)\n",
        "\n",
        "# Decode and save baseline-generated melody\n",
        "baseline_melody = ''.join([itos[token] for token in baseline_generated_tokens])\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(baseline_melody)\n",
        "with open(\"baseline_generated_melody.txt\", \"w\") as f:\n",
        "    f.write(baseline_melody)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: Giovanni Di Liberto\n",
        "Updated by: ChatGPT\n",
        "Description: Read tokens from a text file and play/save the audio.\n",
        "\"\"\"\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import simpleaudio as sa\n",
        "\n",
        "# Define note frequencies (A4 = 440 Hz)\n",
        "NOTE_FREQUENCIES = {\n",
        "    'C': 261.63,\n",
        "    'c': 277.18,  # C#\n",
        "    'D': 293.66,\n",
        "    'd': 311.13,  # D#\n",
        "    'E': 329.63,\n",
        "    'F': 349.23,\n",
        "    'f': 369.99,  # F#\n",
        "    'G': 392.00,\n",
        "    'g': 415.30,  # G#\n",
        "    'A': 440.00,\n",
        "    'a': 466.16,  # A#\n",
        "    'B': 493.88,\n",
        "    'R': 0     # Rest\n",
        "}\n",
        "\n",
        "# Generate a sine wave for a given frequency\n",
        "def generate_sine_wave(frequency, duration_ms, sample_rate=44100, amplitude=0.5):\n",
        "    t = np.linspace(0, duration_ms / 1000, int(sample_rate * duration_ms / 1000), False)\n",
        "    wave = 0.5 * amplitude * np.sin(2 * np.pi * frequency * t)\n",
        "    wave = (wave * 32767).astype(np.int16)\n",
        "    audio_segment = AudioSegment(\n",
        "        wave.tobytes(),\n",
        "        frame_rate=sample_rate,\n",
        "        sample_width=wave.dtype.itemsize,\n",
        "        channels=1\n",
        "    )\n",
        "    return audio_segment\n",
        "\n",
        "# Function to create a sequence of notes\n",
        "def create_sequence(note_sequence, duration_ms=500):\n",
        "    song = AudioSegment.silent(duration=0)\n",
        "    for note in note_sequence:\n",
        "        if note == 'R':  # Handle rest\n",
        "            segment = AudioSegment.silent(duration=duration_ms)\n",
        "        else:\n",
        "            frequency = NOTE_FREQUENCIES.get(note, 0)  # Default to 0 if note not found\n",
        "            segment = generate_sine_wave(frequency, duration_ms)\n",
        "        song += segment\n",
        "    return song\n",
        "\n",
        "# Read sequence from a text file\n",
        "def read_sequence_from_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        # Read all lines and split tokens by whitespace\n",
        "        sequence = file.read().split()\n",
        "    return sequence\n",
        "\n",
        "# Main logic\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the text file containing the note sequence\n",
        "    input_file = \"/content/gpt_generated_melody.txt\"  # Replace with your file path\n",
        "\n",
        "    # Read the sequence from the file\n",
        "    sequence = read_sequence_from_file(input_file)\n",
        "\n",
        "    # Create the audio sequence\n",
        "    song = create_sequence(sequence, duration_ms=500)  # 500ms per note\n",
        "\n",
        "    # Save the song to a .wav file\n",
        "    output_file = \"nursery_rhyme_gpt_10k.wav\"\n",
        "    song.export(output_file, format=\"wav\")\n",
        "    print(f\"Audio file saved as {output_file}\")\n",
        "\n",
        "    # Play the .wav file using simpleaudio\n",
        "    wave_obj = sa.WaveObject.from_wave_file(output_file)\n",
        "    play_obj = wave_obj.play()\n",
        "    play_obj.wait_done()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "pkUvKu4HV5y0",
        "outputId": "befb7543-b0cf-483f-afbf-bc77b3458a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio file saved as nursery_rhyme_gpt_10k.wav\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SimpleaudioError",
          "evalue": "Error opening PCM device. -- CODE: -2 -- MSG: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSimpleaudioError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bf4a8769f366>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Play the .wav file using simpleaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwave_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWaveObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wave_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mplay_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mplay_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/simpleaudio/shiny.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         return play_buffer(self.audio_data, self.num_channels,\n\u001b[0m\u001b[1;32m     20\u001b[0m                            self.bytes_per_sample, self.sample_rate)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/simpleaudio/shiny.py\u001b[0m in \u001b[0;36mplay_buffer\u001b[0;34m(audio_data, num_channels, bytes_per_sample, sample_rate)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     play_id = _sa._play_buffer(audio_data, num_channels, bytes_per_sample,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                sample_rate)\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPlayObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSimpleaudioError\u001b[0m: Error opening PCM device. -- CODE: -2 -- MSG: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation Steps\n",
        "# normalize the dataset\n",
        "# Normalization: Convert all notes to uppercase\n",
        "def normalize_notes(melodies):\n",
        "    normalized = []\n",
        "    for melody in melodies:\n",
        "        normalized.append(melody.strip().upper())  # Convert to uppercase and remove extra spaces\n",
        "    return normalized\n",
        "\n",
        "# Load melodies\n",
        "with open('inputMelodiesAugmented.txt', 'r') as file:\n",
        "    melodies = file.readlines()\n",
        "\n",
        "# Apply normalization\n",
        "normalized_melodies = normalize_notes(melodies)\n",
        "\n",
        "# Save normalized melodies\n",
        "with open('normalizedMelodies.txt', 'w') as file:\n",
        "    for melody in normalized_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Normalization completed. Saved to 'normalizedMelodies.txt'\")\n"
      ],
      "metadata": {
        "id": "12RceLG3WSuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cc6906-ce31-409d-d97f-bb6aadc576a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization completed. Saved to 'normalizedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# introduce rhythm and duration\n",
        "import random\n",
        "\n",
        "# Define rhythmic durations\n",
        "durations = [\"1/4\", \"1/8\", \"1/16\"]\n",
        "\n",
        "# Add rhythm and duration to notes\n",
        "def add_rhythm(melodies):\n",
        "    rhythmic_melodies = []\n",
        "    for melody in melodies:\n",
        "        rhythmic_melody = []\n",
        "        for note in melody.split():\n",
        "            if note != \"R\":  # Only notes get durations, rests remain the same\n",
        "                rhythmic_melody.append(f\"{note}:{random.choice(durations)}\")\n",
        "            else:\n",
        "                rhythmic_melody.append(note)  # Keep rests as is\n",
        "        rhythmic_melodies.append(\" \".join(rhythmic_melody))\n",
        "    return rhythmic_melodies\n",
        "\n",
        "# Apply rhythm\n",
        "rhythmic_melodies = add_rhythm(normalized_melodies)\n",
        "\n",
        "# Save rhythmic melodies\n",
        "with open('rhythmicMelodies.txt', 'w') as file:\n",
        "    for melody in rhythmic_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Rhythm added. Saved to 'rhythmicMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTB_f8u5xVW2",
        "outputId": "a7b1082a-1bfe-44bc-8387-89af63581a8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rhythm added. Saved to 'rhythmicMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ocatve expansion.. transpose melodies into lower and higher ocatves\n",
        "# Define pitch-shifting function\n",
        "def transpose_octave(melodies, shift):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    transposed_melodies = []\n",
        "    for melody in melodies:\n",
        "        transposed_melody = []\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:  # Token with duration\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    transposed_note = notes[(index + shift) % 12]  # Transpose note\n",
        "                    transposed_melody.append(f\"{transposed_note}:{duration}\")\n",
        "                else:\n",
        "                    transposed_melody.append(token)  # Keep rests unchanged\n",
        "            elif token in notes and token != \"R\":  # Plain note\n",
        "                index = notes.index(token)\n",
        "                transposed_note = notes[(index + shift) % 12]\n",
        "                transposed_melody.append(transposed_note)\n",
        "            else:\n",
        "                transposed_melody.append(token)\n",
        "        transposed_melodies.append(\" \".join(transposed_melody))\n",
        "    return transposed_melodies\n",
        "\n",
        "# Apply octave expansion\n",
        "expanded_melodies = []\n",
        "for shift in [-1, 0, 1]:  # Shift down an octave, keep original, shift up an octave\n",
        "    expanded_melodies += transpose_octave(rhythmic_melodies, shift)\n",
        "\n",
        "# Save expanded melodies\n",
        "with open('expandedMelodies.txt', 'w') as file:\n",
        "    for melody in expanded_melodies:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Octave expansion completed. Saved to 'expandedMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cwDhy5RxVZ8",
        "outputId": "eaddaee2-dd36-4cea-94c3-8711c155e9ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Octave expansion completed. Saved to 'expandedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# additional data sugmentation techniques\n",
        "#Apply random pitch-shifting, inversion, and noise injection.\n",
        "# Data Augmentation Techniques\n",
        "\n",
        "# Random pitch shifting\n",
        "def random_pitch_shift(melodies, semitones_range=2):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    shifted_melodies = []\n",
        "    for melody in melodies:\n",
        "        shifted_melody = []\n",
        "        shift = random.randint(-semitones_range, semitones_range)  # Random shift within range\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    shifted_note = notes[(index + shift) % 12]\n",
        "                    shifted_melody.append(f\"{shifted_note}:{duration}\")\n",
        "                else:\n",
        "                    shifted_melody.append(token)\n",
        "            elif token in notes and token != \"R\":\n",
        "                index = notes.index(token)\n",
        "                shifted_note = notes[(index + shift) % 12]\n",
        "                shifted_melody.append(shifted_note)\n",
        "            else:\n",
        "                shifted_melody.append(token)\n",
        "        shifted_melodies.append(\" \".join(shifted_melody))\n",
        "    return shifted_melodies\n",
        "\n",
        "# Invert melody\n",
        "def invert_melody(melodies):\n",
        "    notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\", \"R\"]\n",
        "    inverted_melodies = []\n",
        "    for melody in melodies:\n",
        "        inverted_melody = []\n",
        "        for token in melody.split():\n",
        "            if \":\" in token:\n",
        "                note, duration = token.split(\":\")\n",
        "                if note in notes and note != \"R\":\n",
        "                    index = notes.index(note)\n",
        "                    inverted_note = notes[-(index + 1)]  # Invert by reversing the index\n",
        "                    inverted_melody.append(f\"{inverted_note}:{duration}\")\n",
        "                else:\n",
        "                    inverted_melody.append(token)\n",
        "            else:\n",
        "                inverted_melody.append(token)\n",
        "        inverted_melodies.append(\" \".join(inverted_melody))\n",
        "    return inverted_melodies\n",
        "\n",
        "# Apply augmentations\n",
        "pitch_shifted_melodies = random_pitch_shift(expanded_melodies)\n",
        "inverted_melodies = invert_melody(expanded_melodies)\n",
        "\n",
        "# Combine all augmented datasets\n",
        "augmented_dataset = expanded_melodies + pitch_shifted_melodies + inverted_melodies\n",
        "\n",
        "# Save the final augmented dataset\n",
        "with open('finalAugmentedMelodies.txt', 'w') as file:\n",
        "    for melody in augmented_dataset:\n",
        "        file.write(melody + '\\n')\n",
        "\n",
        "print(\"Data augmentation completed. Saved to 'finalAugmentedMelodies.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkgq6EEExVdB",
        "outputId": "4d426196-19fb-4b80-de61-fa22b8503187"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation completed. Saved to 'finalAugmentedMelodies.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import random\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "dropout = 0.3\n",
        "\n",
        "n_embd = 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "# Gradient clipping threshold\n",
        "grad_clip = 1.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# Load melody data\n",
        "with open('/content/finalAugmentedMelodies.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text = text.replace(' ', '')  # Remove spaces between tokens\n",
        "\n",
        "# Define the vocabulary for musical notes\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from notes/rests to integers\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l])  # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        accuracies = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "\n",
        "            # Reshape logits to match (B, T, C)\n",
        "            B, T = X.shape\n",
        "            logits = logits.view(B, T, -1)  # Restore original shape\n",
        "            predictions = logits.argmax(dim=-1)  # Get predicted indices\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracies[k] = (predictions == Y).float().mean().item()  # Compare predictions with targets\n",
        "\n",
        "        out[split] = {\n",
        "            'loss': losses.mean(),\n",
        "            'accuracy': accuracies.mean()\n",
        "        }\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_perplexity(loss):\n",
        "    return torch.exp(torch.tensor(loss))\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_bleu(reference, candidate):\n",
        "    # BLEU score computation\n",
        "    reference = [list(reference)]  # BLEU expects a list of reference sequences\n",
        "    candidate = list(candidate)\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "# Baseline unigram model\n",
        "def unigram_model(data):\n",
        "    freq = Counter(data.tolist())\n",
        "    total = sum(freq.values())\n",
        "    prob = {k: v / total for k, v in freq.items()}\n",
        "    return prob\n",
        "\n",
        "unigram_probs = unigram_model(train_data)\n",
        "\n",
        "def unigram_generate(length):\n",
        "    return ''.join([itos[random.choices(list(unigram_probs.keys()), list(unigram_probs.values()))[0]] for _ in range(length)])\n",
        "\n",
        "class RelativePositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.encoding = nn.Parameter(torch.zeros(max_len, d_model))\n",
        "\n",
        "        # Initialize positional encodings\n",
        "        nn.init.xavier_uniform_(self.encoding)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape  # Batch size and sequence length\n",
        "        if T > self.max_len:\n",
        "            raise ValueError(\"Sequence length exceeds the maximum length of positional encoding.\")\n",
        "        return self.encoding[:T, :]  # Return encodings for the given sequence length\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)  # (B,T,hs)\n",
        "        q = self.query(x)  # (B,T,hs)\n",
        "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5  # Scaled dot-product attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.relative_pos_encoding = RelativePositionalEncoding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.relative_pos_encoding(idx)  # Adjusted for sequence length\n",
        "        pos_emb = pos_emb.unsqueeze(0).expand(B, -1, -1)  # Match batch size\n",
        "        x = tok_emb + pos_emb  # Combine embeddings\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5, verbose=True)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        metrics = estimate_loss()\n",
        "        perplexity = {split: calculate_perplexity(metrics[split]['loss']) for split in ['train', 'val']}\n",
        "        print(f\"step {iter}: train loss {metrics['train']['loss']:.4f}, val loss {metrics['val']['loss']:.4f}, train perplexity {perplexity['train']:.4f}, val perplexity {perplexity['val']:.4f}, train accuracy {metrics['train']['accuracy']:.4f}, val accuracy {metrics['val']['accuracy']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_melody = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(\"Generated Melody (GPT Model):\")\n",
        "print(generated_melody)\n",
        "\n",
        "reference_melody = decode(val_data[:500].tolist())\n",
        "bleu_score = calculate_bleu(reference_melody, generated_melody)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "unigram_generated = unigram_generate(500)\n",
        "unigram_bleu_score = calculate_bleu(reference_melody, unigram_generated)\n",
        "print(f\"BLEU Score (Unigram Model): {unigram_bleu_score:.4f}\")\n",
        "\n",
        "print(\"Generated Melody (Unigram Model):\")\n",
        "print(unigram_generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFg_ql83xVfs",
        "outputId": "e54dc861-e9ea-4a7e-c97c-7cae151d5273"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.052559 M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-5-250044191036>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(torch.tensor(loss))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.8737, val loss 2.8756, train perplexity 17.7023, val perplexity 17.7355, train accuracy 0.0647, val accuracy 0.0642\n",
            "step 500: train loss 1.5193, val loss 1.5120, train perplexity 4.5690, val perplexity 4.5358, train accuracy 0.4145, val accuracy 0.4185\n",
            "step 1000: train loss 1.1784, val loss 1.1775, train perplexity 3.2491, val perplexity 3.2463, train accuracy 0.5813, val accuracy 0.5820\n",
            "step 1500: train loss 1.1164, val loss 1.1111, train perplexity 3.0537, val perplexity 3.0376, train accuracy 0.6076, val accuracy 0.6098\n",
            "step 2000: train loss 1.0534, val loss 1.0544, train perplexity 2.8674, val perplexity 2.8701, train accuracy 0.6262, val accuracy 0.6261\n",
            "step 2500: train loss 1.0116, val loss 1.0127, train perplexity 2.7500, val perplexity 2.7531, train accuracy 0.6405, val accuracy 0.6405\n",
            "step 3000: train loss 0.9994, val loss 0.9895, train perplexity 2.7167, val perplexity 2.6899, train accuracy 0.6449, val accuracy 0.6490\n",
            "step 3500: train loss 0.9699, val loss 0.9656, train perplexity 2.6377, val perplexity 2.6265, train accuracy 0.6537, val accuracy 0.6553\n",
            "step 4000: train loss 0.9483, val loss 0.9493, train perplexity 2.5813, val perplexity 2.5839, train accuracy 0.6597, val accuracy 0.6596\n",
            "step 4500: train loss 0.9489, val loss 0.9375, train perplexity 2.5829, val perplexity 2.5536, train accuracy 0.6604, val accuracy 0.6646\n",
            "step 4999: train loss 0.9352, val loss 0.9294, train perplexity 2.5477, val perplexity 2.5329, train accuracy 0.6653, val accuracy 0.6675\n",
            "Generated Melody (GPT Model):\n",
            "\n",
            "BCBAABCBAGECCABCBCGEBCBACBAGABBBBGCCBAABBBCBABBBCBABBBCBABBBCBACEBBBAEECBACBCAABCBCRAACACCCCCCCCCCECCCBABCBCACCCCCCCCACCCCBBBAEECBACBBABCBAABDECA:1/4\n",
            "RGFFFFFFFCBGGRGGGRGGGGGGFFFFFFFFFCBGGRGGFFCCCGFFFFFGFFFFFRGGGGFFFFFFFFCBRGFGGRGGGGGGRGGGGFFCCCCGGGAFFFGFFFAAFAFAAFFAFAFAAAAACBGFRGGGGGAFFFRAAAAFDRFFFFFFRCAGFRAGFGCCAGFAGAGGFRGABCCAGFFGFFFFDCAGFFCDFRFFCDFRFFCDFFRFFCDFRFCCEGARFFFFFCDFRFFFCDFFRGGGGGRGGFFFFFFFRBCDFRFFCDFFRFFCDFDFRGGGGGRFFCCCRGFFCRGFGGRCCCRFFFFRFCFFCCDFRFFCDFRFFFCDFFRFFCDFFRFCDFFRCCC:1/\n",
            "BLEU Score: 0.2696\n",
            "BLEU Score (Unigram Model): 0.2428\n",
            "Generated Melody (Unigram Model):\n",
            "ACCARBDFGFGDBCGDGDCCRAGD/GDCCADRADAECADAFEFDGCEDGRAFFCABGCDRRCABEGFEGCADGCFRCEFAGRAGDDADE6EGGCRFDAGAAGCDDBRDRGBCBGDCAFAFGDCDCCFGCFDCCCDFFBDFAADFCDFGRGDCDRAACACGCGCBFGDBDACDEFARB6FRCBFAFCDDFBGFDEFCRGDGDDFFGDFFBGCDGGAAGDCBRGEAAACCABECBFGBGDBRFGGRCEAFEGDAGDAECDFAFAGDCCD:DFFECDDGEDAGGAGERFEGFFADBGACCFCECDFFCGCFAAGFGRFFBBC1CRFBCDEDCECFGERERREFAFRAEDFDCGEG\n",
            "DGFDFRFACCFDFRADRCGRGAAAEAFGBBGGAGAFAD/RGDCFEFDFAFFCAADDFEAFFRADDCGCCBBGCGBCACFREBGCBRFCGFDACAGCBBBDGCCGABDGEDADFAAADFRGGRCDGBDFDGBCEAGFABRRDGDADGA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AW-997blxViL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEqzSExLxVli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}